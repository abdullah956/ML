<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>171b772ba7ee4048b153d4d7ef20aa33</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>1) here i imported libraries that will be used in this
assignment.</p>
</div>
<div class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&quot;BreastCancer.csv&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<pre><code>(569, 32)</code></pre>
</div>
</div>
<div class="cell markdown">
<p>2) loading the dataset and checked it's rows and columns.</p>
</div>
<div class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X , y <span class="op">=</span> data.iloc[:,<span class="dv">2</span>:<span class="dv">32</span>], data[<span class="st">&quot;diagnosis&quot;</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.4</span>, random_state <span class="op">=</span> <span class="dv">28</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>3) here i seprated the dataset into it's features and labels into X
and y respectively. then just performing the train_test_split on X and
y.</p>
</div>
<div class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> LabelEncoder() </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y_train_encoded <span class="op">=</span> encoder.fit_transform(y_train)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>y_test_encoded <span class="op">=</span> encoder.fit_transform(y_test)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>4) here just encoding the orignal labels that were ['B','M'] into
[0,1]</p>
</div>
<div class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler().fit(X_train)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.transform(X_train)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler().fit(X_test)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>5) using standardization on X_train and X_test.</p>
</div>
<div class="cell code" data-execution_count="19">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>x))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogisticRegression():</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, lr<span class="op">=</span><span class="fl">0.001</span>, n_iters<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_iters <span class="op">=</span> n_iters</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        n_samples, n_features <span class="op">=</span> X.shape</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_iters):</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>            linear_pred <span class="op">=</span> np.dot(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> sigmoid(linear_pred)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            dw <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>n_samples) <span class="op">*</span> np.dot(X.T, (predictions <span class="op">-</span> y))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>            db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>n_samples) <span class="op">*</span> np.<span class="bu">sum</span>(predictions<span class="op">-</span>y)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights <span class="op">=</span> <span class="va">self</span>.weights <span class="op">-</span> <span class="va">self</span>.lr<span class="op">*</span>dw</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bias <span class="op">=</span> <span class="va">self</span>.bias <span class="op">-</span> <span class="va">self</span>.lr<span class="op">*</span>db</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        linear_pred <span class="op">=</span> np.dot(X, <span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.bias</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> sigmoid(linear_pred)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        class_pred <span class="op">=</span> [<span class="dv">0</span> <span class="cf">if</span> y<span class="op">&lt;=</span><span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">1</span> <span class="cf">for</span> y <span class="kw">in</span> y_pred]</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> class_pred</span></code></pre></div>
</div>
<div class="cell markdown">
<p>6) builing a logistic regression model.</p>
</div>
<div class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LogisticRegression(lr<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train_scaled,y_train_encoded)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test_scaled)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> np.<span class="bu">sum</span>(y_pred<span class="op">==</span>y_test_encoded)<span class="op">/</span><span class="bu">len</span>(y_test_encoded)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(acc<span class="op">*</span><span class="dv">100</span>,<span class="st">&quot;%&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>94.2982456140351 %
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>7) appling that logistic regression on scaled data and checking the
accuracy.</p>
</div>
<div class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_encoded,y_pred))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.98      0.93      0.95       147
           1       0.89      0.96      0.92        81

    accuracy                           0.94       228
   macro avg       0.93      0.95      0.94       228
weighted avg       0.95      0.94      0.94       228

</code></pre>
</div>
</div>
<div class="cell markdown">
<p>8) here is the classification report of scaled data.</p>
</div>
<div class="cell code" data-execution_count="22">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>preprocessed_data <span class="op">=</span> confusion_matrix (y_test_encoded, y_pred)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(preprocessed_data,annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">&#39;RdBu&#39;</span>, linewidths<span class="op">=</span><span class="fl">.9</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="22">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_fc1d4bf78c754e85bcbe9d9ebe6ad159/f31cb9304689e34781566464e757a411c104dfbd.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>9) simply using a confussion matrix and then applying heatmap to see
the accuracy of logistic regression model on scaled data.</p>
</div>
<div class="cell code" data-execution_count="23">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>clf2 <span class="op">=</span> LogisticRegression(lr<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>clf2.fit(X_train,y_train_encoded)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>y_pred2<span class="op">=</span> clf.predict(X_test)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>acc2<span class="op">=</span> np.<span class="bu">sum</span>(y_pred2<span class="op">==</span>y_test_encoded)<span class="op">/</span><span class="bu">len</span>(y_test_encoded)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(acc2<span class="op">*</span><span class="dv">100</span>,<span class="st">&quot;%&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>35.526315789473685 %
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>10) now applying the logistic regression on orignal unscaled data and
seeing it's accuracy.</p>
</div>
<div class="cell code" data-execution_count="24">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_encoded,y_pred2))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.00      0.00      0.00       147
           1       0.36      1.00      0.52        81

    accuracy                           0.36       228
   macro avg       0.18      0.50      0.26       228
weighted avg       0.13      0.36      0.19       228

</code></pre>
</div>
</div>
<div class="cell markdown">
<p>11) getting the classfication report on unscaled data.</p>
</div>
<div class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>normal_data <span class="op">=</span> confusion_matrix (y_test_encoded, y_pred2)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(normal_data,annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">&#39;RdBu&#39;</span>, linewidths<span class="op">=</span><span class="fl">.9</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="25">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_fc1d4bf78c754e85bcbe9d9ebe6ad159/0a67a929ea10e449ac719b7733d07a7c6c16e567.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>12) using a confussion matrix and then applying heatmap to see the
accuracy of logistic regression model on unscaled data.</p>
</div>
<div class="cell code" data-execution_count="26">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;accuracy on scaled data = &quot;</span>,acc<span class="op">*</span><span class="dv">100</span>,<span class="st">&quot;%&quot;</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;accuracy on unscaled/orignal data = &quot;</span>,acc2<span class="op">*</span><span class="dv">100</span>,<span class="st">&quot;%&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>accuracy on scaled data =  94.2982456140351 %
accuracy on unscaled/orignal data =  35.526315789473685 %
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>13) here you can see that the accuracy of the logistic regression
model is very high "94%" on the preprocessed scaled data. on the other
hand the accuracy of unscaled data is very low "36%". the difference in
accuracy is about "58%"</p>
</div>
</body>
</html>
